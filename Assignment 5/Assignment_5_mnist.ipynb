{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from keras.layers import Flatten, Activation, Dropout, Dense\n",
    "import keras_tuner as kt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n",
      "Shape of y_train before one-hot encoding:  (60000,)\n",
      "Shape of y_test after one-hot encoding:  (10000, 10)\n",
      "Shape of y_subtrain after one-hot encoding:  (50400, 10)\n",
      "Shape of y_valid after one-hot encoding:  (9600, 10)\n"
     ]
    }
   ],
   "source": [
    "mndata = MNIST('mnist')\n",
    "\n",
    "X_train, y_train = mndata.load_training()\n",
    "X_test, y_test = mndata.load_testing()\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "(b) Split the training dataset into sub training and validation sets randomly. Use 1\n",
    "6 of training dataset as validation set. Use the ‘accuracy’ as metric. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X_subtrain, X_valid, y_subtrain, y_valid = train_test_split(X_train, y_train, test_size=0.16, random_state=42)\n",
    "\n",
    "\n",
    "# one-hot encoding of y_train, y_test, y_subtrain, y_valid\n",
    "n_classes = 10\n",
    "print(\"Shape of y_train before one-hot encoding: \", y_train.shape)\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)\n",
    "print(\"Shape of y_test after one-hot encoding: \", y_test.shape)\n",
    "y_subtrain = to_categorical(y_subtrain, n_classes)\n",
    "y_valid = to_categorical(y_valid, n_classes)\n",
    "print(\"Shape of y_subtrain after one-hot encoding: \", y_subtrain.shape)\n",
    "print(\"Shape of y_valid after one-hot encoding: \", y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1575/1575 [==============================] - 6s 3ms/step - loss: 0.3754 - accuracy: 0.8965 - val_loss: 0.2314 - val_accuracy: 0.9319\n",
      "Epoch 2/10\n",
      "1575/1575 [==============================] - 4s 3ms/step - loss: 0.2054 - accuracy: 0.9414 - val_loss: 0.1809 - val_accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "1575/1575 [==============================] - 4s 3ms/step - loss: 0.1638 - accuracy: 0.9529 - val_loss: 0.1632 - val_accuracy: 0.9499\n",
      "Epoch 4/10\n",
      "1575/1575 [==============================] - 5s 3ms/step - loss: 0.1363 - accuracy: 0.9601 - val_loss: 0.1374 - val_accuracy: 0.9603\n",
      "Epoch 5/10\n",
      "1575/1575 [==============================] - 6s 4ms/step - loss: 0.1162 - accuracy: 0.9655 - val_loss: 0.1357 - val_accuracy: 0.9594\n",
      "Epoch 6/10\n",
      "1575/1575 [==============================] - 7s 4ms/step - loss: 0.1032 - accuracy: 0.9691 - val_loss: 0.1256 - val_accuracy: 0.9624\n",
      "Epoch 7/10\n",
      "1575/1575 [==============================] - 4s 3ms/step - loss: 0.0929 - accuracy: 0.9723 - val_loss: 0.1215 - val_accuracy: 0.9636\n",
      "Epoch 8/10\n",
      "1575/1575 [==============================] - 5s 3ms/step - loss: 0.0837 - accuracy: 0.9746 - val_loss: 0.1210 - val_accuracy: 0.9641\n",
      "Epoch 9/10\n",
      "1575/1575 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9772 - val_loss: 0.1206 - val_accuracy: 0.9632\n",
      "Epoch 10/10\n",
      "1575/1575 [==============================] - 5s 3ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 0.1206 - val_accuracy: 0.9635\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please repeat 10 times of random split for each hyper-parameters and architecture, and aggregate\n",
    "(average) the accuracy.\n",
    "\"\"\"\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))                            \n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "history = model.fit(X_subtrain, y_subtrain, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587777853012085"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average accuracy\n",
    "sum(history.history['accuracy']) / len(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nc) (20 points) Optimizer evaluation\\n• Implement a neural network which has single hidden layer with 32 units. Using the network, find best hyper-parameters of the following optimizers; SGD,\\nRMSprop, Adam, Adagrad.\\n• Train the network with the training dataset (not sub training) with the best\\nhyper-parameters of each optimizer.\\n• For each optimizer, report test accuracy using the test dataset.\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\AI_assg5_12\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\AI_assg5_12\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\AI_assg5_12\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.01\n",
      "Score: 0.8998437523841858\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.1\n",
      "Score: 0.863177090883255\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(c) (20 points) Optimizer evaluation\n",
    "• Implement a neural network which has single hidden layer with 32 units. Using the network, find best hyper-parameters of the following \n",
    "optimizers; SGD, RMSprop, Adam, Adagrad.\n",
    "• Train the network with the training dataset (not sub training) with the best\n",
    "hyper-parameters of each optimizer.\n",
    "• For each optimizer, report test accuracy using the test dataset.\n",
    "\"\"\"\n",
    "\n",
    "# tuning adam_model\n",
    "\n",
    "def adam_model(hp):\n",
    "    tuned_model = Sequential()\n",
    "    tuned_model.add(Dense(32, Flatten(input_shape=(784,))))\n",
    "    tuned_model.add(Dense(10))\n",
    "    tuned_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    tuned_model.compile(\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            hp.Choice('lr', values=[0.001, 0.01, 0.1])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return tuned_model\n",
    "\n",
    "\n",
    "\n",
    "adam_tuner = RandomSearch(\n",
    "    adam_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='AI_assg5_12'\n",
    ")\n",
    "\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=2, validation_data=(X_test, y_test))\n",
    "adam_tuner.search(X_subtrain, y_subtrain, epochs=5, validation_data=(X_valid, y_valid))\n",
    "adam_tuner.results_summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0893 - accuracy: 0.8834 - val_loss: 0.0777 - val_accuracy: 0.9020\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0800 - accuracy: 0.8979 - val_loss: 0.0813 - val_accuracy: 0.8939\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0782 - accuracy: 0.9017 - val_loss: 0.0749 - val_accuracy: 0.9038\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0764 - accuracy: 0.9035 - val_loss: 0.0744 - val_accuracy: 0.9033\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0753 - accuracy: 0.9051 - val_loss: 0.0725 - val_accuracy: 0.9082\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0751 - accuracy: 0.9051 - val_loss: 0.0726 - val_accuracy: 0.9143\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0749 - accuracy: 0.9062 - val_loss: 0.0763 - val_accuracy: 0.9034\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0744 - accuracy: 0.9061 - val_loss: 0.0764 - val_accuracy: 0.9072\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0742 - accuracy: 0.9076 - val_loss: 0.0799 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0746 - accuracy: 0.9073 - val_loss: 0.0739 - val_accuracy: 0.9083\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07389047741889954, 0.90829998254776]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the network with the training dataset (not sub training) with the best\n",
    "hyper-parameters of each optimizer. For each optimizer, report test accuracy using the test dataset.\n",
    "\"\"\"\n",
    "\n",
    "# adam optimizer - training the model using best learning rate of 0.01 and evaluating on test data\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "hp.values['lr'] = 0.01\n",
    "adam_model = adam_model(hp)\n",
    "history = adam_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "adam_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\AI_assg5_2\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\AI_assg5_2\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\AI_assg5_2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.001\n",
      "Score: 0.9138541519641876\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.01\n",
      "Score: 0.9013020694255829\n"
     ]
    }
   ],
   "source": [
    "# tuning RMSprop_model\n",
    "\n",
    "def RMSprop_model(hp):\n",
    "    tuned_model = Sequential()\n",
    "    tuned_model.add(Dense(32, Flatten(input_shape=(784,))))\n",
    "    tuned_model.add(Dense(10))\n",
    "    tuned_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    tuned_model.compile(\n",
    "        optimizer = keras.optimizers.RMSprop(\n",
    "            hp.Choice('lr', values=[0.001, 0.01, 0.1])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return tuned_model\n",
    "\n",
    "RMSprop_tuner = RandomSearch(\n",
    "    RMSprop_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='AI_assg5_2'\n",
    ")\n",
    "\n",
    "RMSprop_tuner.search(X_subtrain, y_subtrain, epochs=5, validation_data=(X_valid, y_valid))\n",
    "RMSprop_tuner.results_summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0904 - accuracy: 0.8812 - val_loss: 0.0692 - val_accuracy: 0.9106\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0696 - accuracy: 0.9098 - val_loss: 0.0658 - val_accuracy: 0.9149\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9139 - val_loss: 0.0646 - val_accuracy: 0.9179\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0662 - accuracy: 0.9161 - val_loss: 0.0649 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0657 - accuracy: 0.9173 - val_loss: 0.0661 - val_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0655 - accuracy: 0.9174 - val_loss: 0.0651 - val_accuracy: 0.9211\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0652 - accuracy: 0.9182 - val_loss: 0.0665 - val_accuracy: 0.9151\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0650 - accuracy: 0.9190 - val_loss: 0.0661 - val_accuracy: 0.9168\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0648 - accuracy: 0.9200 - val_loss: 0.0661 - val_accuracy: 0.9186\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0647 - accuracy: 0.9203 - val_loss: 0.0668 - val_accuracy: 0.9137\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0668 - accuracy: 0.9137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06679161638021469, 0.9136999845504761]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSprop optimizer - training the model using best learning rate of 0.001 and evaluating on test data\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "hp.values['lr'] = 0.001\n",
    "RMSprop_model = RMSprop_model(hp)\n",
    "history = RMSprop_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "RMSprop_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\AI_assg5_31\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\AI_assg5_31\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\AI_assg5_31\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.1\n",
      "Score: 0.9045486052831014\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.01\n",
      "Score: 0.8551041682561239\n"
     ]
    }
   ],
   "source": [
    "# tuning SGD_model \n",
    "\n",
    "def SGD_model(hp):\n",
    "    tuned_model = Sequential()\n",
    "    tuned_model.add(Dense(32, Flatten(input_shape=(784,))))\n",
    "    tuned_model.add(Dense(10))\n",
    "    tuned_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    tuned_model.compile(\n",
    "        optimizer = keras.optimizers.SGD(\n",
    "            hp.Choice('lr', values=[0.001, 0.01, 0.1])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return tuned_model\n",
    "\n",
    "SGD_tuner = RandomSearch(\n",
    "    SGD_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='AI_assg5_31'\n",
    ")\n",
    "\n",
    "SGD_tuner.search(X_subtrain, y_subtrain, epochs=5, validation_data=(X_valid, y_valid))\n",
    "SGD_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1307 - accuracy: 0.8292 - val_loss: 0.0877 - val_accuracy: 0.8920\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.8903 - val_loss: 0.0756 - val_accuracy: 0.9058\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0768 - accuracy: 0.8986 - val_loss: 0.0714 - val_accuracy: 0.9049\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0732 - accuracy: 0.9026 - val_loss: 0.0687 - val_accuracy: 0.9126\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0711 - accuracy: 0.9066 - val_loss: 0.0680 - val_accuracy: 0.9120\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9087 - val_loss: 0.0665 - val_accuracy: 0.9140\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0686 - accuracy: 0.9106 - val_loss: 0.0670 - val_accuracy: 0.9148\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9110 - val_loss: 0.0654 - val_accuracy: 0.9177\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0673 - accuracy: 0.9125 - val_loss: 0.0651 - val_accuracy: 0.9168\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0668 - accuracy: 0.9144 - val_loss: 0.0651 - val_accuracy: 0.9148\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0651 - accuracy: 0.9148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06513335555791855, 0.9147999882698059]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD optimizer - training the model using best learning rate of 0.1 and evaluating on test data\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "hp.values['lr'] = 0.1\n",
    "SGD_model = SGD_model(hp)\n",
    "history = SGD_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "SGD_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\AI_assg5_5\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\AI_assg5_5\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\AI_assg5_5\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.1\n",
      "Score: 0.9118229150772095\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "lr: 0.001\n",
      "Score: 0.7615624964237213\n"
     ]
    }
   ],
   "source": [
    "# tuning adagrad_model\n",
    "\n",
    "def adagrad_model(hp):\n",
    "    tuned_model = Sequential()\n",
    "    tuned_model.add(Dense(32, Flatten(input_shape=(784,))))\n",
    "    tuned_model.add(Dense(10))\n",
    "    tuned_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    tuned_model.compile(\n",
    "        optimizer = keras.optimizers.Adagrad(\n",
    "            hp.Choice('lr', values=[0.001, 0.01, 0.1])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return tuned_model\n",
    "\n",
    "adagrad_tuner = RandomSearch(\n",
    "    adagrad_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=2,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='AI_assg5_5'\n",
    ")\n",
    "\n",
    "adagrad_tuner.search(X_subtrain, y_subtrain, epochs=5, validation_data=(X_valid, y_valid))\n",
    "adagrad_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0977 - accuracy: 0.8719 - val_loss: 0.0723 - val_accuracy: 0.9070\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0731 - accuracy: 0.9042 - val_loss: 0.0696 - val_accuracy: 0.9121\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9097 - val_loss: 0.0667 - val_accuracy: 0.9129\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0680 - accuracy: 0.9115 - val_loss: 0.0689 - val_accuracy: 0.9097\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0671 - accuracy: 0.9135 - val_loss: 0.0648 - val_accuracy: 0.9164\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0663 - accuracy: 0.9151 - val_loss: 0.0642 - val_accuracy: 0.9175\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0657 - accuracy: 0.9156 - val_loss: 0.0647 - val_accuracy: 0.9188\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0652 - accuracy: 0.9173 - val_loss: 0.0644 - val_accuracy: 0.9162\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0648 - accuracy: 0.9179 - val_loss: 0.0642 - val_accuracy: 0.9181\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0646 - accuracy: 0.9183 - val_loss: 0.0646 - val_accuracy: 0.9198\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0646 - accuracy: 0.9198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0645749419927597, 0.9197999835014343]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adagrad optimizer - training the model using best learning rate of 0.1 and evaluating on test data\n",
    "\n",
    "# adagrad_model = Sequential()\n",
    "# adagrad_model.add(Dense(32, input_shape=(784,)))\n",
    "# adagrad_model.add(Activation('relu'))                            \n",
    "# adagrad_model.add(Dense(10))\n",
    "# adagrad_model.add(Activation('softmax'))\n",
    "\n",
    "hp = kt.HyperParameters()\n",
    "hp.values['lr'] = 0.1\n",
    "adagrad_model = adagrad_model(hp)\n",
    "history = adagrad_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "adagrad_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 01m 02s]\n",
      "val_accuracy: 0.9696875015894572\n",
      "\n",
      "Best val_accuracy So Far: 0.972083330154419\n",
      "Total elapsed time: 00h 03m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in my_dir\\AI_assg5_67\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_of_layers: 5\n",
      "num_of_neurons0: 96\n",
      "activation_function0: relu\n",
      "num_of_neurons1: 64\n",
      "activation_function1: relu\n",
      "num_of_neurons2: 96\n",
      "activation_function2: sigmoid\n",
      "num_of_neurons3: 32\n",
      "activation_function3: relu\n",
      "num_of_neurons4: 32\n",
      "activation_function4: relu\n",
      "Score: 0.972083330154419\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_of_layers: 3\n",
      "num_of_neurons0: 96\n",
      "activation_function0: relu\n",
      "num_of_neurons1: 32\n",
      "activation_function1: sigmoid\n",
      "num_of_neurons2: 96\n",
      "activation_function2: sigmoid\n",
      "num_of_neurons3: 96\n",
      "activation_function3: tanh\n",
      "num_of_neurons4: 32\n",
      "activation_function4: sigmoid\n",
      "Score: 0.9696875015894572\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_of_layers: 3\n",
      "num_of_neurons0: 128\n",
      "activation_function0: sigmoid\n",
      "num_of_neurons1: 96\n",
      "activation_function1: relu\n",
      "num_of_neurons2: 32\n",
      "activation_function2: relu\n",
      "Score: 0.9693749944368998\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "(d) (20 points) Architecture evaluation\n",
    "• Pick the best optimizer and it’s hyper-parameters from the previous part.\n",
    "• Using sub training and validation datasets, find the best architecture in terms\n",
    "of the number of layers, the number of units, and activation functions.\n",
    "• Report 3 best architectures in terms of test accuracy. Please include architecture diagram as shown in Figure 1.\n",
    "\"\"\"\n",
    "\n",
    "# best model - RMSprop_model, accuracy - 0.96, lr = 0.001\n",
    "\n",
    "def best_model(hp):\n",
    "    tuned_model = Sequential()\n",
    "    tuned_model.add(Flatten(input_shape=(784,)))\n",
    "\n",
    "    for i in range(hp.Int('num_of_layers',2,5)):         \n",
    "        #providing range for number of neurons in hidden layers\n",
    "        tuned_model.add(Dense(units=hp.Int('num_of_neurons'+ str(i),min_value=32,max_value=128,step=32),\n",
    "                                    activation=hp.Choice('activation_function' + str(i), values=['relu', 'tanh', 'sigmoid'], default='relu')))\n",
    "\n",
    "    tuned_model.add(Dense(10))\n",
    "    tuned_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    tuned_model.compile(\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return tuned_model\n",
    "\n",
    "best_tuner = RandomSearch(\n",
    "    best_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='AI_assg5_67'\n",
    ")\n",
    "\n",
    "best_tuner.search(X_subtrain, y_subtrain, epochs=5, validation_data=(X_valid, y_valid))\n",
    "best_tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "id = 7\n",
    "\n",
    "image = np.array(X_train[id], dtype='float')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# print(X_train[id])\n",
    "print(y_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

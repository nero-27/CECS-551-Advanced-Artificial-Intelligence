{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48008a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the files\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "label_names = unpickle('cifar-10-batches-py/batches.meta')[b'label_names']\n",
    "training_files = ['data_batch_2','data_batch_3','data_batch_4','data_batch_5']\n",
    "\n",
    "training_dict = unpickle('cifar-10-batches-py/data_batch_1')\n",
    "\n",
    "training_data = training_dict[b'data']\n",
    "training_labels = training_dict[b'labels']\n",
    "\n",
    "for f in training_files:\n",
    "    training_dict = unpickle('cifar-10-batches-py/'+f)\n",
    "    training_data = np.concatenate((training_data,training_dict[b'data']),axis=0)\n",
    "    training_labels += training_dict[b'labels']\n",
    "\n",
    "test_dict = unpickle('cifar-10-batches-py/test_batch')\n",
    "\n",
    "test_data = test_dict[b'data']\n",
    "test_labels = test_dict[b'labels']\n",
    "\n",
    "def dataToIMG(arr):\n",
    "    RGBsort = np.stack(np.hsplit(arr,3),2)\n",
    "    IMGsort = np.swapaxes(np.swapaxes(np.stack(np.split(RGBsort,32,1),3),2,3),1,2)\n",
    "    return IMGsort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f8c65",
   "metadata": {},
   "source": [
    "b'batch_label' \n",
    "   &emsp;Ignore since we don't use their batches\n",
    "\n",
    "b'labels'\n",
    "    &emsp;Our output data\n",
    "\n",
    "b'data'\n",
    "    &emsp;Our input data, values go from 0 to 255\n",
    "\n",
    "b'filenames'\n",
    "    &emsp;Ignore since filenames aren't needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1525d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ship'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "picID = 2\n",
    "\n",
    "plt.imshow(dataToIMG(test_data)[picID])\n",
    "print(label_names[test_labels[picID]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bf453",
   "metadata": {},
   "source": [
    "Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1307883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 393,162\n",
      "Trainable params: 392,266\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model1.add(layers.BatchNormalization())\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(128, activation='relu'))\n",
    "model1.add(layers.Dense(10, activation='softmax'))\n",
    "model1.summary()\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.001,momentum=0.9),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b7fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 97s 155ms/step - loss: 1.5265 - acc: 0.4568 - val_loss: 1.2447 - val_acc: 0.5565\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 97s 155ms/step - loss: 1.0978 - acc: 0.6082 - val_loss: 1.0658 - val_acc: 0.6235\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 97s 156ms/step - loss: 0.9308 - acc: 0.6700 - val_loss: 1.0695 - val_acc: 0.6235\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 94s 151ms/step - loss: 0.8112 - acc: 0.7117 - val_loss: 0.9500 - val_acc: 0.6666\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 94s 151ms/step - loss: 0.7200 - acc: 0.7485 - val_loss: 0.9274 - val_acc: 0.6788\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.6406 - acc: 0.7767 - val_loss: 0.8831 - val_acc: 0.6977\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 90s 145ms/step - loss: 0.5716 - acc: 0.8002 - val_loss: 0.8874 - val_acc: 0.6995\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.5078 - acc: 0.8248 - val_loss: 0.8575 - val_acc: 0.7139\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 92s 147ms/step - loss: 0.4444 - acc: 0.8464 - val_loss: 0.8453 - val_acc: 0.7224\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.3894 - acc: 0.8659 - val_loss: 0.9047 - val_acc: 0.7079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7309174984693527"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"training\")\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"validation\")\n",
    "\n",
    "history = model1.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)\n",
    "\n",
    "np.mean(history.history[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ec3a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.9397 - acc: 0.6965\n"
     ]
    }
   ],
   "source": [
    "img_test_data = dataToIMG(test_data)\n",
    "img_test_labels = utils.to_categorical(test_labels)\n",
    "\n",
    "model1.evaluate(\n",
    "    x=img_test_data,\n",
    "    y=img_test_labels)[1]\n",
    "\n",
    "model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d2bfc",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c07078",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8d34fe62b47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model2.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',\n\u001b[0;32m      3\u001b[0m                         input_shape=(32, 32, 3)))\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Dropout(0.2)) \n",
    "\n",
    "model2.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Dropout(0.2)) \n",
    "\n",
    "model2.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model2.add(layers.BatchNormalization())\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Dropout(0.2))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(1024, activation='relu'))\n",
    "model2.add(layers.Dense(512, activation='relu'))\n",
    "model2.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(0.001,0.91,0.01,1e-07,False),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd3cdb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 1.5413 - acc: 0.4865 - val_loss: 1.0763 - val_acc: 0.6143\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.9829 - acc: 0.6566 - val_loss: 0.8976 - val_acc: 0.6891\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.8366 - acc: 0.7117 - val_loss: 0.8960 - val_acc: 0.6905\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 0.7527 - acc: 0.7413 - val_loss: 0.8488 - val_acc: 0.7205\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.6833 - acc: 0.7656 - val_loss: 0.7234 - val_acc: 0.7524\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.6323 - acc: 0.7850 - val_loss: 0.8020 - val_acc: 0.7490\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.5807 - acc: 0.8000 - val_loss: 0.7477 - val_acc: 0.7570\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 87s 139ms/step - loss: 0.5457 - acc: 0.8150 - val_loss: 0.6995 - val_acc: 0.7711\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.5046 - acc: 0.8270 - val_loss: 0.7589 - val_acc: 0.7665\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 89s 142ms/step - loss: 0.4656 - acc: 0.8424 - val_loss: 0.7653 - val_acc: 0.7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7431174874305725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"training\")\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"validation\")\n",
    "\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)\n",
    "\n",
    "np.mean(history.history[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84b63cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.8208 - acc: 0.7666: 2s - loss: 0.8091 - \n"
     ]
    }
   ],
   "source": [
    "img_test_data = dataToIMG(test_data)\n",
    "img_test_labels = utils.to_categorical(test_labels)\n",
    "\n",
    "model2.evaluate(\n",
    "    x=img_test_data,\n",
    "    y=img_test_labels)[1]\n",
    "\n",
    "model2.save('model2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856c65b",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6f05ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 32)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 16, 16, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 8, 8, 128)         65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 657,866\n",
      "Trainable params: 655,946\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(32, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "\n",
    "model3.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "\n",
    "model3.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "\n",
    "model3.add(layers.Conv2D(256, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.Conv2D(256, (2, 2), activation='relu', padding='same',))\n",
    "model3.add(layers.BatchNormalization())\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Dropout(0.2))\n",
    "\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(128, activation='relu'))\n",
    "model3.add(layers.Dense(10, activation='softmax'))\n",
    "model3.summary()\n",
    "\n",
    "model3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(0.001,0.905,0.991,1e-06,False),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054a9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 93s 148ms/step - loss: 1.6026 - acc: 0.4136 - val_loss: 1.2452 - val_acc: 0.5578\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 94s 150ms/step - loss: 1.1223 - acc: 0.5976 - val_loss: 1.0240 - val_acc: 0.6442\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 93s 149ms/step - loss: 0.9265 - acc: 0.6709 - val_loss: 0.9256 - val_acc: 0.6746\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 91s 146ms/step - loss: 0.8006 - acc: 0.7171 - val_loss: 0.7831 - val_acc: 0.7254\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 91s 145ms/step - loss: 0.7112 - acc: 0.7488 - val_loss: 0.7452 - val_acc: 0.7430\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.6471 - acc: 0.7729 - val_loss: 0.7000 - val_acc: 0.7606\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 90s 144ms/step - loss: 0.5869 - acc: 0.7936 - val_loss: 0.6707 - val_acc: 0.7677\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 88s 141ms/step - loss: 0.5419 - acc: 0.8095 - val_loss: 0.6075 - val_acc: 0.7933\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 87s 140ms/step - loss: 0.5038 - acc: 0.8215 - val_loss: 0.5791 - val_acc: 0.8032\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 89s 143ms/step - loss: 0.4665 - acc: 0.8361 - val_loss: 0.5991 - val_acc: 0.7997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7181524991989136"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"training\")\n",
    "\n",
    "validation_generator = datagen.flow(\n",
    "    dataToIMG(training_data), \n",
    "    utils.to_categorical(training_labels), \n",
    "    batch_size=64,\n",
    "    subset=\"validation\")\n",
    "\n",
    "history = model3.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator)\n",
    "\n",
    "np.mean(history.history[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6271400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6303 - acc: 0.7924\n"
     ]
    }
   ],
   "source": [
    "img_test_data = dataToIMG(test_data)\n",
    "img_test_labels = utils.to_categorical(test_labels)\n",
    "\n",
    "model3.evaluate(\n",
    "    x=img_test_data,\n",
    "    y=img_test_labels)[1]\n",
    "\n",
    "model3.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb60cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
